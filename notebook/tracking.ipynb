{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install ultralytics filterpy nest_asyncio motmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNBU6u6qj-N6",
        "outputId": "e93bb4af-ce73-42c5-c1e8-5c8b3a2477d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.247-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting filterpy\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/178.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Collecting motmetrics\n",
            "  Downloading motmetrics-1.4.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cpu)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pandas>=0.23.1 in /usr/local/lib/python3.12/dist-packages (from motmetrics) (2.2.2)\n",
            "Collecting xmltodict>=0.12.0 (from motmetrics)\n",
            "  Downloading xmltodict-1.0.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.23.1->motmetrics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.23.1->motmetrics) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.247-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading motmetrics-1.4.0-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m161.5/161.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Downloading xmltodict-1.0.2-py3-none-any.whl (13 kB)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110460 sha256=e43020d87d226c2160f307222f406a1cea8f43a0190228e26720d82bfee0455c\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/bf/4c/b0c3f4798a0166668752312a67118b27a3cd341e13ac0ae6ee\n",
            "Successfully built filterpy\n",
            "Installing collected packages: xmltodict, ultralytics-thop, motmetrics, filterpy, ultralytics\n",
            "Successfully installed filterpy-1.4.5 motmetrics-1.4.0 ultralytics-8.3.247 ultralytics-thop-2.0.18 xmltodict-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class: GMC (Global Motion Compensation)\n",
        "\n",
        "**M√¥ t·∫£:**\n",
        "L·ªõp x·ª≠ l√Ω b√π tr·ª´ chuy·ªÉn ƒë·ªông n·ªÅn cho video (ƒë·∫∑c bi·ªát h·ªØu √≠ch cho UAV/Drone). S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p *Sparse Optical Flow* ƒë·ªÉ ∆∞·ªõc l∆∞·ª£ng chuy·ªÉn ƒë·ªông c·ªßa camera v√† cƒÉn ch·ªânh l·∫°i h·ªá t·ªça ƒë·ªô cho c√°c ƒë·ªëi t∆∞·ª£ng ƒëang theo d√µi.\n",
        "\n",
        "**Ph∆∞∆°ng ph√°p:**\n",
        "1. **Downscaling:** Gi·∫£m ƒë·ªô ph√¢n gi·∫£i ·∫£nh ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω.\n",
        "2. **Feature Detection:** S·ª≠ d·ª•ng thu·∫≠t to√°n *FAST* ƒë·ªÉ t√¨m ƒëi·ªÉm ƒë·∫∑c tr∆∞ng.\n",
        "3. **Matching:** S·ª≠ d·ª•ng *Lucas-Kanade Optical Flow* ƒë·ªÉ kh·ªõp ƒëi·ªÉm gi·ªØa 2 frames li√™n ti·∫øp.\n",
        "4. **Transformation:** D√πng *RANSAC* (trong `estimateAffinePartial2D`) ƒë·ªÉ lo·∫°i b·ªè nhi·ªÖu v√† t√≠nh ma tr·∫≠n Affine.\n"
      ],
      "metadata": {
        "id": "NpScGpqAHnUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "from filterpy.kalman import KalmanFilter\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import motmetrics as mm\n",
        "\n",
        "\n",
        "if not hasattr(np, 'asfarray'):\n",
        "    np.asfarray = lambda x: np.asarray(x, dtype=np.float64)\n",
        "\n",
        "class GMC:\n",
        "    def __init__(self, downscale=2):\n",
        "        self.downscale = downscale\n",
        "        self.detector = cv2.FastFeatureDetector_create(threshold=20)\n",
        "        self.prev_gray = None\n",
        "        self.prev_kps = None\n",
        "    def apply(self, raw_frame, tracks):\n",
        "        height, width = raw_frame.shape[:2]\n",
        "        frame_gray = cv2.cvtColor(raw_frame, cv2.COLOR_BGR2GRAY)\n",
        "        if self.downscale > 1: frame_gray = cv2.resize(frame_gray, (width // self.downscale, height // self.downscale))\n",
        "        kps = self.detector.detect(frame_gray, None)\n",
        "        kps = np.float32([kp.pt for kp in kps])\n",
        "\n",
        "        if self.prev_gray is None or self.prev_kps is None or len(self.prev_kps) == 0 or len(kps) == 0:\n",
        "            self.prev_gray = frame_gray; self.prev_kps = kps; return tracks\n",
        "        p1, st, err = cv2.calcOpticalFlowPyrLK(self.prev_gray, frame_gray, self.prev_kps, None)\n",
        "\n",
        "\n",
        "        if p1 is not None:\n",
        "            status = st.flatten() == 1; good_old = self.prev_kps[status]; good_new = p1[status]\n",
        "        else: good_old = np.array([]); good_new = np.array([])\n",
        "\n",
        "\n",
        "        if len(good_old) < 10: self.prev_gray = frame_gray; self.prev_kps = kps; return tracks\n",
        "        m, inliers = cv2.estimateAffinePartial2D(good_old, good_new)\n",
        "\n",
        "\n",
        "        if m is not None:\n",
        "            if self.downscale > 1: m[0, 2] *= self.downscale; m[1, 2] *= self.downscale\n",
        "            for track in tracks: track.apply_gmc(m)\n",
        "        self.prev_gray = frame_gray; self.prev_kps = kps\n",
        "        return tracks"
      ],
      "metadata": {
        "id": "ARVRTmtc1fCV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "359c4718-52f5-4c48-b979-98be6304a994"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class: KalmanBoxTracker\n",
        "\n",
        "**M√¥ t·∫£:**\n",
        "L·ªõp qu·∫£n l√Ω tr·∫°ng th√°i c·ªßa t·ª´ng ƒë·ªëi t∆∞·ª£ng (Track) ri√™ng bi·ªát b·∫±ng b·ªô l·ªçc Kalman (Kalman Filter). Class n√†y ch·ªãu tr√°ch nhi·ªám kh·ªüi t·∫°o, d·ª± ƒëo√°n v·ªã tr√≠ m·ªõi, v√† c·∫≠p nh·∫≠t v·ªã tr√≠ khi c√≥ ph√°t hi·ªán (detection) m·ªõi. ƒê·∫∑c bi·ªát, n√≥ ƒë∆∞·ª£c t√≠ch h·ª£p kh·∫£ nƒÉng th√≠ch nghi v·ªõi nhi·ªÖu (Adaptive Noise) v√† b√π tr·ª´ chuy·ªÉn ƒë·ªông n·ªÅn (GMC).\n",
        "\n",
        "**Kh√¥ng gian tr·∫°ng th√°i (State Space):**\n",
        "M·ªói ƒë·ªëi t∆∞·ª£ng ƒë∆∞·ª£c m√¥ h√¨nh h√≥a b·ªüi vector tr·∫°ng th√°i 7 chi·ªÅu ($dim\\_x=7$):\n",
        "$$\\mathbf{x} = [u, v, s, r, \\dot{u}, \\dot{v}, \\dot{s}]^T$$\n",
        "Trong ƒë√≥:\n",
        "- $(u, v)$: T·ªça ƒë·ªô t√¢m c·ªßa h·ªôp bao.\n",
        "- $s$: Di·ªán t√≠ch h·ªôp bao ($area = w \\times h$).\n",
        "- $r$: T·ª∑ l·ªá khung h√¨nh ($ratio = w/h$).\n",
        "- $\\dot{u}, \\dot{v}, \\dot{s}$: V·∫≠n t·ªëc bi·∫øn thi√™n c·ªßa t√¢m v√† di·ªán t√≠ch.\n",
        "\n",
        "**C√°c ph∆∞∆°ng th·ª©c ch√≠nh:**\n",
        "\n",
        "### 1. `__init__(self, bbox)`\n",
        "Kh·ªüi t·∫°o b·ªô l·ªçc Kalman cho m·ªôt ƒë·ªëi t∆∞·ª£ng m·ªõi.\n",
        "- **Thi·∫øt l·∫≠p ma tr·∫≠n:**\n",
        "  - `F` (Transition Matrix): Ma tr·∫≠n chuy·ªÉn tr·∫°ng th√°i, m√¥ h√¨nh h√≥a chuy·ªÉn ƒë·ªông v·ªõi v·∫≠n t·ªëc kh√¥ng ƒë·ªïi.\n",
        "  - `H` (Measurement Matrix): Ma tr·∫≠n ƒëo l∆∞·ªùng, √°nh x·∫° tr·∫°ng th√°i sang kh√¥ng gian quan s√°t (ch·ªâ ƒëo ƒë∆∞·ª£c $u, v, s, r$).\n",
        "  - `P, R, Q`: C√°c ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai nhi·ªÖu.\n",
        "- **Tr·∫°ng th√°i:** Kh·ªüi t·∫°o `age=0`, `hits=0`, `state=0` (Tentative - ch∆∞a x√°c nh·∫≠n).\n",
        "\n",
        "### 2. `apply_gmc(self, warp_matrix)`\n",
        "**Ch·ª©c nƒÉng quan tr·ªçng:** C·∫≠p nh·∫≠t l·∫°i v·ªã tr√≠ $(u, v)$ c·ªßa ƒë·ªëi t∆∞·ª£ng d·ª±a tr√™n chuy·ªÉn ƒë·ªông c·ªßa Camera.\n",
        "- **Input:** Ma tr·∫≠n bi·∫øn ƒë·ªïi Affine $2 \\times 3$ t·ª´ module GMC.\n",
        "- **Logic:** Nh√¢n vector v·ªã tr√≠ $[u, v, 1]$ v·ªõi ma tr·∫≠n bi·∫øn ƒë·ªïi ƒë·ªÉ \"d·ªùi\" ƒë·ªëi t∆∞·ª£ng v·ªÅ ƒë√∫ng v·ªã tr√≠ trong h·ªá t·ªça ƒë·ªô m·ªõi tr∆∞·ªõc khi th·ª±c hi·ªán d·ª± ƒëo√°n.\n",
        "\n",
        "### 3. `update(self, bbox, confidence=None)`\n",
        "C·∫≠p nh·∫≠t tr·∫°ng th√°i b·ªô l·ªçc khi c√≥ k·∫øt qu·∫£ ph√°t hi·ªán (Detection) m·ªõi t·ª´ YOLO.\n",
        "- **Adaptive Measurement Noise (Th√≠ch nghi nhi·ªÖu):**\n",
        "  N·∫øu c√≥ `confidence` (ƒë·ªô tin c·∫≠y), h·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh ma tr·∫≠n nhi·ªÖu ƒëo l∆∞·ªùng `R`.\n",
        "  - *Confidence th·∫•p* $\\rightarrow$ TƒÉng `R` $\\rightarrow$ Tin v√†o d·ª± ƒëo√°n (Predict) h∆°n.\n",
        "  - *Confidence cao* $\\rightarrow$ Gi·∫£m `R` $\\rightarrow$ Tin v√†o ph√°t hi·ªán (Detection) h∆°n.\n",
        "- **Chuy·ªÉn tr·∫°ng th√°i:** N·∫øu ƒë·ªëi t∆∞·ª£ng xu·∫•t hi·ªán li√™n ti·∫øp 3 l·∫ßn (`hits >= 3`), chuy·ªÉn t·ª´ `Tentative` (0) sang `Confirmed` (1).\n",
        "\n",
        "### 4. `predict(self)`\n",
        "D·ª± ƒëo√°n tr·∫°ng th√°i ·ªü khung h√¨nh ti·∫øp theo.\n",
        "- TƒÉng tu·ªïi (`age`) c·ªßa qu·ªπ ƒë·∫°o.\n",
        "- N·∫øu m·∫•t d·∫•u (`time_since_update > 0`), reset chu·ªói `hit_streak` v·ªÅ 0.\n",
        "- Tr·∫£ v·ªÅ h·ªôp bao d·ª± ƒëo√°n.\n",
        "\n",
        "### Helper Methods (Static)\n",
        "- `convert_bbox_to_z(bbox)`: Chuy·ªÉn ƒë·ªïi t·ª´ `[x1, y1, x2, y2]` sang kh√¥ng gian tr·∫°ng th√°i `[u, v, s, r]`.\n",
        "- `convert_x_to_bbox(x)`: Chuy·ªÉn ng∆∞·ª£c l·∫°i t·ª´ kh√¥ng gian tr·∫°ng th√°i v·ªÅ h·ªôp bao chu·∫©n ƒë·ªÉ hi·ªÉn th·ªã.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "uikSA-0hJH_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KalmanBoxTracker:\n",
        "    count = 0\n",
        "    def __init__(self, bbox):\n",
        "        self.kf = KalmanFilter(dim_x=7, dim_z=4)\n",
        "        self.kf.F = np.array([[1,0,0,0,1,0,0], [0,1,0,0,0,1,0], [0,0,1,0,0,0,1],[0,0,0,1,0,0,0],  [0,0,0,0,1,0,0], [0,0,0,0,0,1,0], [0,0,0,0,0,0,1]])\n",
        "        self.kf.H = np.array([[1,0,0,0,0,0,0], [0,1,0,0,0,0,0], [0,0,1,0,0,0,0], [0,0,0,1,0,0,0]])\n",
        "        self.kf.R[2:,2:] *= 10.; self.kf.P[4:,4:] *= 1000.; self.kf.P *= 10.\n",
        "        self.kf.Q[-1,-1] *= 0.01; self.kf.Q[4:,4:] *= 0.01\n",
        "        self.kf.x[:4] = self.convert_bbox_to_z(bbox)\n",
        "        self.time_since_update = 0; self.id = KalmanBoxTracker.count\n",
        "        KalmanBoxTracker.count += 1; self.history = []; self.hits = 0; self.hit_streak = 0; self.age = 0; self.state = 0\n",
        "    def apply_gmc(self, warp_matrix):\n",
        "        pos = np.array([self.kf.x[0, 0], self.kf.x[1, 0], 1.0])\n",
        "        new_pos = warp_matrix @ pos\n",
        "        self.kf.x[0, 0] = new_pos[0]; self.kf.x[1, 0] = new_pos[1]\n",
        "    def update(self, bbox, confidence=None):\n",
        "        self.time_since_update = 0; self.history = []; self.hits += 1; self.hit_streak += 1\n",
        "        if confidence:\n",
        "            r_factor = (1.0 - confidence) * 20.0\n",
        "            self.kf.R = np.diag([1., 1., 10., 10.]) + np.diag([r_factor, r_factor, r_factor, r_factor])\n",
        "        self.kf.update(self.convert_bbox_to_z(bbox))\n",
        "        if self.state == 0 and self.hits >= 3: self.state = 1\n",
        "    def predict(self):\n",
        "        if((self.kf.x[6, 0] + self.kf.x[2, 0]) <= 0): self.kf.x[6, 0] *= 0.0\n",
        "        self.kf.predict(); self.age += 1\n",
        "        if(self.time_since_update > 0): self.hit_streak = 0\n",
        "        self.time_since_update += 1\n",
        "        self.history.append(self.convert_x_to_bbox(self.kf.x))\n",
        "        return self.history[-1]\n",
        "    def get_state(self):\n",
        "        return self.convert_x_to_bbox(self.kf.x)\n",
        "    @staticmethod\n",
        "    def convert_bbox_to_z(bbox):\n",
        "        w = bbox[2] - bbox[0]; h = bbox[3] - bbox[1]; x = bbox[0] + w/2.; y = bbox[1] + h/2.\n",
        "        s = w * h; r = w / float(h); return np.array([x, y, s, r]).reshape((4, 1))\n",
        "    @staticmethod\n",
        "    def convert_x_to_bbox(x, score=None):\n",
        "        w = np.sqrt(x[2] * x[3]); h = x[2] / w\n",
        "        if(score is None): return np.array([x[0]-w/2., x[1]-h/2., x[0]+w/2., x[1]+h/2.]).reshape((1,4))\n",
        "        else: return np.array([x[0]-w/2., x[1]-h/2., x[0]+w/2., x[1]+h/2., score]).reshape((1,5))\n"
      ],
      "metadata": {
        "id": "SrNOxA8o2bjK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Module: Data Association & Utilities\n",
        "\n",
        "Module n√†y cung c·∫•p c√°c c√¥ng c·ª• to√°n h·ªçc v√† x·ª≠ l√Ω d·ªØ li·ªáu c·∫ßn thi·∫øt ƒë·ªÉ li√™n k·∫øt c√°c ph√°t hi·ªán (detections) v·ªõi c√°c qu·ªπ ƒë·∫°o (trackers).\n",
        "\n",
        "### 1. H√†m `iou_batch(bb_test, bb_gt)`\n",
        "**M√¥ t·∫£:**\n",
        "T√≠nh to√°n ch·ªâ s·ªë IoU (Intersection over Union) gi·ªØa hai t·∫≠p h·ª£p c√°c h·ªôp bao (Bounding Boxes) m·ªôt c√°ch song song (vectorized operation) s·ª≠ d·ª•ng Numpy broadcasting. ƒê√¢y l√† phi√™n b·∫£n t·ªëi ∆∞u t·ªëc ƒë·ªô cao thay v√¨ d√πng v√≤ng l·∫∑p `for`.\n",
        "\n",
        "**Tham s·ªë:**\n",
        "- `bb_test`: M·∫£ng Numpy `(N, 4)` ch·ª©a c√°c h·ªôp bao d·ª± ƒëo√°n (Detections).\n",
        "- `bb_gt`: M·∫£ng Numpy `(M, 4)` ch·ª©a c√°c h·ªôp bao th·ª±c t·∫ø (Trackers).\n",
        "\n",
        "**C∆° ch·∫ø:**\n",
        "S·ª≠ d·ª•ng k·ªπ thu·∫≠t `expand_dims` ƒë·ªÉ t·∫°o ma tr·∫≠n so s√°nh k√≠ch th∆∞·ªõc `(N, M)`, cho ph√©p t√≠nh to√°n ƒë·ªìng th·ªùi di·ªán t√≠ch giao (Intersection) v√† di·ªán t√≠ch h·ª£p (Union) c·ªßa t·∫•t c·∫£ c√°c c·∫∑p c√≥ th·ªÉ.\n",
        "\n",
        "**Tr·∫£ v·ªÅ:**\n",
        "- Ma tr·∫≠n `(N, M)` ch·ª©a gi√° tr·ªã IoU (t·ª´ 0.0 ƒë·∫øn 1.0) c·ªßa t·ª´ng c·∫∑p.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. H√†m `associate_detections_to_trackers`\n",
        "**M√¥ t·∫£:**\n",
        "Th·ª±c hi·ªán gh√©p n·ªëi (Matching) gi·ªØa c√°c ph√°t hi·ªán m·ªõi v√† c√°c qu·ªπ ƒë·∫°o hi·ªán c√≥ d·ª±a tr√™n ma tr·∫≠n IoU.\n",
        "\n",
        "**Thu·∫≠t to√°n:**\n",
        "1. **T√≠nh Ma tr·∫≠n IoU:** G·ªçi `iou_batch` ƒë·ªÉ l·∫•y ƒë·ªô ch·ªìng l·∫•n gi·ªØa m·ªçi c·∫∑p Detection-Tracker.\n",
        "2. **Hungarian Algorithm:**\n",
        "   - N·∫øu ma tr·∫≠n ƒë∆°n gi·∫£n (m·ªói h√†ng/c·ªôt ch·ªâ c√≥ 1 gi√° tr·ªã v∆∞·ª£t ng∆∞·ª°ng), th·ª±c hi·ªán gh√©p tr·ª±c ti·∫øp.\n",
        "   - N·∫øu ph·ª©c t·∫°p (xung ƒë·ªôt), s·ª≠ d·ª•ng thu·∫≠t to√°n `linear_sum_assignment` (Hungarian) t·ª´ th∆∞ vi·ªán `scipy` ƒë·ªÉ t√¨m ph∆∞∆°ng √°n gh√©p c·∫∑p t·ªëi ∆∞u (t·ªïng IoU l·ªõn nh·∫•t).\n",
        "3. **L·ªçc theo ng∆∞·ª°ng (Thresholding):**\n",
        "   - Lo·∫°i b·ªè c√°c c·∫∑p gh√©p c√≥ `IoU < iou_threshold` (m·∫∑c ƒë·ªãnh 0.3). Coi nh∆∞ kh√¥ng kh·ªõp.\n",
        "4. **Ph√¢n lo·∫°i ƒë·∫ßu ra:**\n",
        "   - `matches`: C√°c c·∫∑p ƒë√£ gh√©p th√†nh c√¥ng.\n",
        "   - `unmatched_detections`: C√°c ph√°t hi·ªán m·ªõi kh√¥ng kh·ªõp v·ªõi ai (s·∫Ω t·∫°o Track m·ªõi).\n",
        "   - `unmatched_trackers`: C√°c qu·ªπ ƒë·∫°o c≈© kh√¥ng t√¨m th·∫•y ƒë·ªëi t∆∞·ª£ng (c√≥ th·ªÉ ƒë√£ b·ªã m·∫•t d·∫•u).\n",
        "\n",
        "**Tham s·ªë:**\n",
        "- `detections`: Danh s√°ch h·ªôp bao t·ª´ YOLO.\n",
        "- `trackers`: Danh s√°ch h·ªôp bao d·ª± ƒëo√°n t·ª´ Kalman Filter.\n",
        "- `iou_threshold`: Ng∆∞·ª°ng ch·ªìng l·∫•n t·ªëi thi·ªÉu ƒë·ªÉ ch·∫•p nh·∫≠n gh√©p c·∫∑p (M·∫∑c ƒë·ªãnh: 0.3).\n",
        "\n",
        "---\n",
        "\n",
        "### 3. H√†m `load_mot_gt(gt_path)`\n",
        "**M√¥ t·∫£:**\n",
        "ƒê·ªçc v√† ph√¢n t√≠ch file d·ªØ li·ªáu Ground Truth (GT) theo chu·∫©n MOTChallenge (MOT15/16/17/20) ƒë·ªÉ ph·ª•c v·ª• vi·ªác ƒë√°nh gi√°.\n",
        "\n",
        "**ƒê·ªãnh d·∫°ng h·ªó tr·ª£:**\n",
        "H·ªó tr·ª£ c·∫£ file CSV (ph√¢n c√°ch b·∫±ng d·∫•u ph·∫©y) v√† file text ph√¢n c√°ch b·∫±ng kho·∫£ng tr·∫Øng. C·∫•u tr√∫c d√≤ng ti√™u chu·∫©n:\n",
        "`frame, id, bb_left, bb_top, bb_width, bb_height, conf, x, y, z`\n",
        "\n",
        "**X·ª≠ l√Ω:**\n",
        "- T·ª± ƒë·ªông ph√°t hi·ªán ƒë·ªãnh d·∫°ng ph√¢n c√°ch (ph·∫©y ho·∫∑c kho·∫£ng tr·∫Øng).\n",
        "- Chuy·ªÉn ƒë·ªïi t·ªça ƒë·ªô t·ª´ `[x, y, w, h]` (chu·∫©n MOT) sang `[x1, y1, x2, y2]` (chu·∫©n x·ª≠ l√Ω n·ªôi b·ªô).\n",
        "- Gom nh√≥m d·ªØ li·ªáu theo t·ª´ng `frame` ƒë·ªÉ truy xu·∫•t nhanh (`dict key = frame_id`).\n",
        "\n",
        "**Tr·∫£ v·ªÅ:**\n",
        "- `gt_dict`: Dictionary d·∫°ng `{frame_id: [[x1, y1, x2, y2, obj_id], ...]}`."
      ],
      "metadata": {
        "id": "1ZLvZ4HuJp6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def iou_batch(bb_test, bb_gt):\n",
        "    bb_gt = np.expand_dims(bb_gt, 0); bb_test = np.expand_dims(bb_test, 1)\n",
        "    xx1 = np.maximum(bb_test[..., 0], bb_gt[..., 0]); yy1 = np.maximum(bb_test[..., 1], bb_gt[..., 1])\n",
        "    xx2 = np.minimum(bb_test[..., 2], bb_gt[..., 2]); yy2 = np.minimum(bb_test[..., 3], bb_gt[..., 3])\n",
        "    w = np.maximum(0., xx2 - xx1); h = np.maximum(0., yy2 - yy1); wh = w * h\n",
        "    o = wh / ((bb_test[..., 2] - bb_test[..., 0]) * (bb_test[..., 3] - bb_test[..., 1]) + (bb_gt[..., 2] - bb_gt[..., 0]) * (bb_gt[..., 3] - bb_gt[..., 1]) - wh)\n",
        "    return(o)\n",
        "\n",
        "def associate_detections_to_trackers(detections, trackers, iou_threshold=0.3):\n",
        "    if(len(trackers)==0): return np.empty((0,2),dtype=int), np.arange(len(detections)), np.empty((0,),dtype=int)\n",
        "    iou_matrix = iou_batch(detections, trackers)\n",
        "    if min(iou_matrix.shape) > 0:\n",
        "        a = (iou_matrix > iou_threshold).astype(np.int32)\n",
        "        if a.sum(1).max() == 1 and a.sum(0).max() == 1: matched_indices = np.stack(np.where(a), axis=1)\n",
        "        else: row_ind, col_ind = linear_sum_assignment(-iou_matrix); matched_indices = np.stack((row_ind, col_ind), axis=1)\n",
        "    else: matched_indices = np.empty((0,2),dtype=int)\n",
        "    unmatched_detections = [d for d, det in enumerate(detections) if d not in matched_indices[:,0]]\n",
        "    unmatched_trackers = [t for t, trk in enumerate(trackers) if t not in matched_indices[:,1]]\n",
        "    matches = []\n",
        "    for m in matched_indices:\n",
        "        if(iou_matrix[m[0], m[1]] < iou_threshold): unmatched_detections.append(m[0]); unmatched_trackers.append(m[1])\n",
        "        else: matches.append(m.reshape(1,2))\n",
        "    if(len(matches)==0): matches = np.empty((0,2),dtype=int)\n",
        "    else: matches = np.concatenate(matches, axis=0)\n",
        "    return matches, np.array(unmatched_detections, dtype=int), np.array(unmatched_trackers, dtype=int)\n",
        "\n",
        "def load_mot_gt(gt_path):\n",
        "    if gt_path is None: return {}\n",
        "    if hasattr(gt_path, 'name'): gt_path = gt_path.name\n",
        "    gt_dict = {}\n",
        "    try:\n",
        "        try: df = pd.read_csv(gt_path, header=None, sep=',')\n",
        "        except: df = pd.read_csv(gt_path, header=None, sep=r'\\s+', engine='python')\n",
        "        for index, row in df.iterrows():\n",
        "            try:\n",
        "                if not str(row[0]).replace('.','',1).isdigit(): continue\n",
        "                frame = int(float(row[0])); obj_id = int(float(row[1]))\n",
        "                x1, y1, w, h = float(row[2]), float(row[3]), float(row[4]), float(row[5])\n",
        "                if frame not in gt_dict: gt_dict[frame] = []\n",
        "                gt_dict[frame].append([x1, y1, x1+w, y1+h, obj_id])\n",
        "            except ValueError: continue\n",
        "    except Exception as e: print(f\"GT Error: {e}\"); return {}\n",
        "    return gt_dict"
      ],
      "metadata": {
        "id": "FdjaFdFA2fIO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_OPTIONS = {\n",
        "    \"EfficientNetB0\": \"/content/drive/MyDrive/tracking/efficientnetB0-yolov8.pt\",\n",
        "    \"EfficientNetB3\": \"/content/drive/MyDrive/tracking/efficientnetB0-yolov8.pt\",\n",
        "    \"MobileNet\": \"yolov8s.pt\",\n",
        "    \"ConvNext-T\": \"/content/drive/MyDrive/tracking/convnext_T_best.pt\",\n",
        "    \"ConvNext-S\": \"/content/drive/MyDrive/tracking/convnext_S_best.pt\"\n",
        "}\n",
        "\n",
        "\n",
        "def detect_objects_frame_1(video_path, model_name):\n",
        "    \"\"\"\n",
        "    Ch·∫°y YOLO tr√™n frame 1, c·∫Øt ·∫£nh c√°c ƒë·ªëi t∆∞·ª£ng detected.\n",
        "    Tr·∫£ v·ªÅ: List ·∫£nh (cho Gallery) v√† List bbox (l∆∞u v√†o State ƒë·ªÉ d√πng sau).\n",
        "    \"\"\"\n",
        "    if video_path is None: return [], [], []\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    ret, frame = cap.read()\n",
        "    cap.release()\n",
        "\n",
        "    if not ret: return [], [], []\n",
        "\n",
        "    # Load model\n",
        "    model_path = MODEL_OPTIONS.get(model_name, \"yolov8n.pt\")\n",
        "    try: model = YOLO(model_path)\n",
        "    except: model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "    # Detect\n",
        "    results = model(frame, verbose=False, iou=0.45, conf=0.1)[0]\n",
        "\n",
        "    gallery_images = []\n",
        "    detected_boxes = [] # L∆∞u coordinate th·ª±c t·∫ø [x1, y1, x2, y2]\n",
        "\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    if results.boxes:\n",
        "        for i, box in enumerate(results.boxes):\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
        "            crop = frame_rgb[y1:y2, x1:x2]\n",
        "            gallery_images.append((crop, f\"Object {i}\"))\n",
        "            detected_boxes.append([x1, y1, x2, y2])\n",
        "\n",
        "    # Reset selected indices state khi scan m·ªõi\n",
        "    return gallery_images, detected_boxes, []\n",
        "\n",
        "def on_select_object(evt: gr.SelectData, detected_boxes, current_selection_indices):\n",
        "    \"\"\"\n",
        "    H√†m Toggle ch·ªçn nhi·ªÅu ƒë·ªëi t∆∞·ª£ng.\n",
        "    \"\"\"\n",
        "    if current_selection_indices is None:\n",
        "        current_selection_indices = []\n",
        "\n",
        "    index = evt.index\n",
        "\n",
        "    # Toggle logic: N·∫øu ƒë√£ c√≥ th√¨ x√≥a, ch∆∞a c√≥ th√¨ th√™m\n",
        "    if index in current_selection_indices:\n",
        "        current_selection_indices.remove(index)\n",
        "    else:\n",
        "        current_selection_indices.append(index)\n",
        "\n",
        "    # S·∫Øp x·∫øp l·∫°i cho ƒë·∫πp\n",
        "    current_selection_indices.sort()\n",
        "\n",
        "    # L·∫•y danh s√°ch c√°c box t∆∞∆°ng ·ª©ng\n",
        "    selected_boxes = [detected_boxes[i] for i in current_selection_indices if i < len(detected_boxes)]\n",
        "\n",
        "    feedback_str = f\"ƒêang ch·ªçn c√°c Object: {current_selection_indices}\" if current_selection_indices else \"Ch∆∞a ch·ªçn ƒë·ªëi t∆∞·ª£ng n√†o (S·∫Ω track t·∫•t c·∫£)\"\n",
        "\n",
        "    return feedback_str, current_selection_indices, selected_boxes\n",
        "\n",
        "def clear_selection():\n",
        "    return \"ƒê√£ x√≥a ch·ªçn. Tracking t·∫•t c·∫£.\", [], []\n",
        "\n",
        "def calculate_iou_single(box1, box2):\n",
        "    # box: [x1, y1, x2, y2]\n",
        "    xx1 = max(box1[0], box2[0]); yy1 = max(box1[1], box2[1])\n",
        "    xx2 = min(box1[2], box2[2]); yy2 = min(box1[3], box2[3])\n",
        "    w = max(0, xx2 - xx1); h = max(0, yy2 - yy1)\n",
        "    inter = w * h\n",
        "    area1 = (box1[2]-box1[0])*(box1[3]-box1[1])\n",
        "    area2 = (box2[2]-box2[0])*(box2[3]-box2[1])\n",
        "    union = area1 + area2 - inter\n",
        "    return inter/union if union > 0 else 0"
      ],
      "metadata": {
        "id": "GamoDCle1wE0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_tracking_demo(video_path, gt_path, model_selection, conf_threshold, iou_threshold, target_boxes_list, progress=gr.Progress()):\n",
        "    if video_path is None: return None, \"Vui l√≤ng upload video.\"\n",
        "\n",
        "    model_path = MODEL_OPTIONS.get(model_selection, model_selection)\n",
        "\n",
        "    target_track_ids = set()\n",
        "    is_selective_mode = target_boxes_list is not None and len(target_boxes_list) > 0\n",
        "\n",
        "    if is_selective_mode:\n",
        "        print(f\"üéØ S·ªë l∆∞·ª£ng targets c·∫ßn kh√≥a: {len(target_boxes_list)}\")\n",
        "\n",
        "    try: model = YOLO(model_path)\n",
        "    except: model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    width, height = int(cap.get(3)), int(cap.get(4))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    if fps < 1: fps = 30.0\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    output_path = \"temp_output.mp4\"\n",
        "    final_output_path = \"result_video.mp4\"\n",
        "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "    gt_data = load_mot_gt(gt_path); has_gt = len(gt_data) > 0\n",
        "    acc = mm.MOTAccumulator(auto_id=True)\n",
        "    trackers = []; gmc = GMC(downscale=2); KalmanBoxTracker.count = 0\n",
        "    frame_idx = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "        frame_idx += 1\n",
        "        if frame_idx % 10 == 0: progress(frame_idx / total_frames, desc=f\"Processing {frame_idx}/{total_frames}\")\n",
        "\n",
        "        results = model(frame, verbose=False, iou=0.45, conf=0.1)[0]\n",
        "        dets = []\n",
        "        if results.boxes:\n",
        "             for box in results.boxes:\n",
        "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "                score = float(box.conf[0].cpu().numpy())\n",
        "                dets.append([x1, y1, x2, y2, score])\n",
        "        dets = np.array(dets) if len(dets) > 0 else np.empty((0, 5))\n",
        "\n",
        "        gmc.apply(frame, trackers)\n",
        "\n",
        "        trks = np.zeros((len(trackers), 5)); to_del = []\n",
        "        for t, trk in enumerate(trks):\n",
        "            pos = trackers[t].predict()[0]\n",
        "            trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]\n",
        "            if np.any(np.isnan(pos)): to_del.append(t)\n",
        "        trks = np.ma.compress_rows(np.ma.masked_invalid(trks))\n",
        "        for t in reversed(to_del): trackers.pop(t)\n",
        "\n",
        "        if len(dets) > 0:\n",
        "            inds_high = dets[:, 4] >= conf_threshold\n",
        "            inds_low = (dets[:, 4] > 0.1) & (dets[:, 4] < conf_threshold)\n",
        "            dets_high = dets[inds_high]; dets_low = dets[inds_low]\n",
        "        else: dets_high = np.empty((0, 5)); dets_low = np.empty((0, 5))\n",
        "\n",
        "        matched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(dets_high, trks, iou_threshold)\n",
        "\n",
        "        trks_remain = trks[unmatched_trks]; dets_remain = dets_low\n",
        "        if len(trks_remain) > 0 and len(dets_remain) > 0:\n",
        "            matched_l, _, _ = associate_detections_to_trackers(dets_remain, trks_remain, 0.1)\n",
        "            for m in matched_l: trackers[unmatched_trks[m[1]]].update(dets_remain[m[0]][:4], dets_remain[m[0]][4])\n",
        "        for m in matched: trackers[m[1]].update(dets_high[m[0]][:4], dets_high[m[0]][4])\n",
        "        for i in unmatched_dets: trackers.append(KalmanBoxTracker(dets_high[i][:4]))\n",
        "\n",
        "        i = len(trackers); ret_trackers = []\n",
        "        for trk in reversed(trackers):\n",
        "            d = trk.get_state()[0]\n",
        "            if (trk.time_since_update < 1) and (trk.hit_streak >= 3 or frame_idx <= 3):\n",
        "                ret_trackers.append(np.concatenate((d,[trk.id])).reshape(1,-1))\n",
        "            i -= 1\n",
        "            if(trk.time_since_update > 30): trackers.pop(i)\n",
        "\n",
        "        if frame_idx == 1 and is_selective_mode and len(ret_trackers) > 0:\n",
        "            for target_box in target_boxes_list:\n",
        "                best_iou = 0\n",
        "                best_id = -1\n",
        "                for trk_data in ret_trackers:\n",
        "                    d = trk_data[0]\n",
        "                    trk_box = [d[0], d[1], d[2], d[3]]\n",
        "                    iou = calculate_iou_single(target_box, trk_box)\n",
        "                    if iou > best_iou:\n",
        "                        best_iou = iou\n",
        "                        best_id = int(d[4])\n",
        "\n",
        "                if best_iou > 0.5:\n",
        "                    target_track_ids.add(best_id)\n",
        "\n",
        "            print(f\"üéØ ƒê√£ kh√≥a c√°c ID: {target_track_ids}\")\n",
        "\n",
        "            if len(target_track_ids) == 0:\n",
        "                print(\"‚ö†Ô∏è Kh√¥ng kh·ªõp ƒë∆∞·ª£c ID n√†o. Chuy·ªÉn sang track all.\")\n",
        "                is_selective_mode = False\n",
        "\n",
        "        if has_gt:\n",
        "            t_ids = []; t_boxes = []\n",
        "            for trk_data in ret_trackers:\n",
        "                d = trk_data[0]\n",
        "                t_ids.append(int(d[4]))\n",
        "                t_boxes.append([d[0], d[1], d[2]-d[0], d[3]-d[1]])\n",
        "            g_ids = []; g_boxes = []\n",
        "            if frame_idx in gt_data:\n",
        "                for item in gt_data[frame_idx]:\n",
        "                    g_ids.append(int(item[4]))\n",
        "                    g_boxes.append([item[0], item[1], item[2]-item[0], item[3]-item[1]])\n",
        "            dist = mm.distances.iou_matrix(g_boxes, t_boxes, max_iou=0.5) if (len(g_boxes)>0 and len(t_boxes)>0) else []\n",
        "            acc.update(g_ids, t_ids, dist)\n",
        "\n",
        "        # --- Draw ---\n",
        "        for d in ret_trackers:\n",
        "            d = d[0]\n",
        "            x1, y1, x2, y2, tid = int(d[0]), int(d[1]), int(d[2]), int(d[3]), int(d[4])\n",
        "\n",
        "            should_draw = True\n",
        "            color = (0, 255, 0)\n",
        "            thickness = 2\n",
        "\n",
        "            if is_selective_mode:\n",
        "                if tid in target_track_ids:\n",
        "                    color = (0, 0, 255)\n",
        "                    thickness = 3\n",
        "                else:\n",
        "                    should_draw = False\n",
        "\n",
        "            if should_draw:\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)\n",
        "                label = f\"TARGET {tid}\" if (is_selective_mode and tid in target_track_ids) else f\"ID {tid}\"\n",
        "                cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release(); out.release()\n",
        "\n",
        "    metrics_str = \"Metrics:\"\n",
        "    if has_gt:\n",
        "        mh = mm.metrics.create()\n",
        "        try:\n",
        "            summary = mh.compute(acc, metrics=['num_frames', 'mota', 'motp', 'idf1', 'mostly_tracked', 'mostly_lost', 'num_switches'], name='acc')\n",
        "            metrics_str = mm.io.render_summary(summary, formatters=mh.formatters, namemap={'num_frames': 'Frames', 'mota': 'MOTA', 'motp': 'MOTP', 'idf1': 'IDF1', 'mostly_tracked': 'MT', 'mostly_lost': 'ML', 'num_switches': 'ID Sw'})\n",
        "        except: metrics_str = \"Error calculating metrics\"\n",
        "\n",
        "    if os.path.exists(final_output_path): os.remove(final_output_path)\n",
        "    try: subprocess.call(args=f\"ffmpeg -y -i {output_path} -c:v libx264 {final_output_path} -loglevel quiet\", shell=True)\n",
        "    except: final_output_path = output_path\n",
        "    return final_output_path, metrics_str\n",
        "\n",
        "\n",
        "with gr.Blocks(title=\"UAV Tracking System\") as demo:\n",
        "    gr.Markdown(\"# UAV Multi-Target Tracking\")\n",
        "    gr.Markdown(\"Upload video -> Qu√©t -> Click ch·ªçn nhi·ªÅu ƒë·ªëi t∆∞·ª£ng (Click l·∫ßn n·ªØa ƒë·ªÉ b·ªè ch·ªçn) -> Start.\")\n",
        "\n",
        "    # 1. Danh s√°ch t·∫•t c·∫£ box detect ƒë∆∞·ª£c ·ªü frame 1\n",
        "    detected_boxes_state = gr.State([])\n",
        "    # 2. Danh s√°ch index c·ªßa c√°c object ƒë√£ click ch·ªçn (VD: [0, 3, 5])\n",
        "    selected_indices_state = gr.State([])\n",
        "    # 3. Danh s√°ch coordinate th·ª±c t·∫ø c·ªßa c√°c object ƒë√£ ch·ªçn (Output cho model)\n",
        "    selected_boxes_state = gr.State([])\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            input_video = gr.Video(label=\"1. Upload Video\")\n",
        "            model_dd = gr.Dropdown(choices=list(MODEL_OPTIONS.keys()), value=\"EfficientNetB0\", label=\"Model\")\n",
        "\n",
        "            with gr.Row():\n",
        "                btn_scan = gr.Button(\"Qu√©t ƒë·ªëi t∆∞·ª£ng\", variant=\"secondary\")\n",
        "                btn_clear = gr.Button(\"X√≥a ch·ªçn\", variant=\"stop\")\n",
        "\n",
        "            gr.Markdown(\"### 3. Gallery (Click ƒë·ªÉ Ch·ªçn/B·ªè ch·ªçn):\")\n",
        "            gallery = gr.Gallery(\n",
        "                label=\"Danh s√°ch ƒë·ªëi t∆∞·ª£ng\",\n",
        "                show_label=True,\n",
        "                elem_id=\"gallery\",\n",
        "                columns=4, rows=2, height=\"auto\",\n",
        "                object_fit=\"contain\",\n",
        "                allow_preview=False\n",
        "            )\n",
        "            selection_info = gr.Textbox(label=\"Tr·∫°ng th√°i ch·ªçn\", value=\"Ch∆∞a ch·ªçn (Track All)\", interactive=False)\n",
        "\n",
        "            with gr.Row():\n",
        "                conf_slide = gr.Slider(0.1, 0.9, 0.5, label=\"Conf Threshold\")\n",
        "                iou_slide = gr.Slider(0.1, 0.9, 0.2, label=\"IoU Threshold\")\n",
        "\n",
        "            input_gt = gr.File(label=\"Upload GT (.txt)\")\n",
        "            btn_run = gr.Button(\"START TRACKING\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            output_video = gr.Video(label=\"K·∫øt qu·∫£ Tracking\")\n",
        "            output_metrics = gr.Textbox(label=\"Metrics Report\", lines=10)\n",
        "\n",
        "\n",
        "    btn_scan.click(\n",
        "        fn=detect_objects_frame_1,\n",
        "        inputs=[input_video, model_dd],\n",
        "        outputs=[gallery, detected_boxes_state, selected_indices_state]\n",
        "    )\n",
        "\n",
        "    gallery.select(\n",
        "        fn=on_select_object,\n",
        "        inputs=[detected_boxes_state, selected_indices_state],\n",
        "        outputs=[selection_info, selected_indices_state, selected_boxes_state]\n",
        "    )\n",
        "\n",
        "    btn_clear.click(\n",
        "        fn=clear_selection,\n",
        "        inputs=[],\n",
        "        outputs=[selection_info, selected_indices_state, selected_boxes_state]\n",
        "    )\n",
        "\n",
        "    btn_run.click(\n",
        "        fn=run_tracking_demo,\n",
        "        inputs=[input_video, input_gt, model_dd, conf_slide, iou_slide, selected_boxes_state],\n",
        "        outputs=[output_video, output_metrics]\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qrhN9K08tNOJ",
        "outputId": "359e5a44-ba66-4910-c660-cb063e5ecbff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://001cb474ec5ef41e5d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://001cb474ec5ef41e5d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1139, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 107, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 119, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 105, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 385, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 284, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7d160fe81f40 [unset]> is bound to a different event loop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ S·ªë l∆∞·ª£ng targets c·∫ßn kh√≥a: 1\n",
            "üéØ ƒê√£ kh√≥a c√°c ID: {0}\n"
          ]
        }
      ]
    }
  ]
}